<br/>
<h1 align="center">ProtTrans</h1>
<br/>

<br/>

[ProtTrans](https://github.com/agemagician/ProtTrans/) is providing **state of the art pre-trained models for proteins**. ProtTrans was trained on **thousands of GPUs from Summit** and **hundreds of Google TPUs** using various **Transformers Models**.

Have a look at our paper [ProtTrans: cracking the language of lifeâ€™s code through self-supervised deep learning and high performance computing](https://arxiv.com/) for more information about our work. 

<br/>
<p align="center">
    <img width="70%" src="https://github.com/agemagician/ProtTrans/raw/master/images/transformers_attention.png" alt="ProtTrans Attention Visualization">
</p>
<br/>


This repository will be updated regulary with **new pre-trained models for proteins** as part of supporting **bioinformatics** community in general, and **Covid-19 research** specifically through our [Accelerate SARS-CoV-2 research with transfer learning using pre-trained language modeling models](https://covid19-hpc-consortium.org/projects/5ed56e51a21132007ebf57bf) project.

Table of Contents
=================
* [ ğŸš€&nbsp; Usage ](#usage)
  * [ ğŸ§¬&nbsp; Feature Extraction ](#feature-extraction)
  * [ ğŸ§&nbsp; Visualization ](#visualization)
  * [ ğŸ“ˆ&nbsp; Benchmark ](#benchmark)
* [ â¤ï¸&nbsp; Community and Contributions ](#community)
* [ ğŸ“«&nbsp; Have a question? ](#question)
* [ ğŸ¤&nbsp; Found a bug? ](#bug)
* [ âœ…&nbsp; Requirements ](#requirements)
* [ ğŸ¤µ&nbsp; Team ](#team)
* [ ğŸ’°&nbsp; Sponsor ](#sponsor)
* [ ğŸ“˜&nbsp; License ](#license)
* [ âœï¸&nbsp; Citation ](#citation)

<a name="usage"></a>
## ğŸš€&nbsp; Usage  

How to use.

<a name="feature-extraction"></a>
 * <b>ğŸ§¬&nbsp; Feature Extraction:</b><br/>

<a name="visualization"></a>
* <b>ğŸ§&nbsp; Visualization:</b><br/> 

<a name="benchmark"></a>
* <b>ğŸ“ˆ&nbsp; Benchmark:</b><br/> 

<a name="community"></a>
## â¤ï¸&nbsp; Community and Contributions

The ProtTrans project is a **open source project** supported by various partner companies and research institutions. We are committed to **share all our pre-trained models and knowledge**. We are more than happy if you could help us on sharing new ptrained models, fixing bugs, proposing new feature, improving our documentation, spreading the word, or support our project.

<a name="question"></a>
## ğŸ“«&nbsp; Have a question?

We are happy to hear your question in our issues page [ProtTrans](https://github.com/agemagician/ProtTrans/issues)! Obviously if you have a private question or want to cooperate with us, you can always **reach out to us directly** via our [RostLab email](mailto:assistant@rostlab.org?subject=[GitHub]ProtTrans) 

<a name="bug"></a>
## ğŸ¤&nbsp; Found a bug?

Feel free to **file a new issue** with a respective title and description on the the [ProtTrans](https://github.com/agemagician/ProtTrans/issues) repository. If you already found a solution to your problem, **we would love to review your pull request**!.

<a name="requirements"></a>
## âœ…&nbsp; Requirements

For protein feature extraction or fine-tuninng our pre-trained models, [Pytorch](https://github.com/pytorch/pytorch) and [Transformers](https://github.com/huggingface/transformers) library from huggingface is needed. For model visualization, you need to install [BertViz](https://github.com/jessevig/bertviz) library.

<a name="team"></a>
## ğŸ¤µ&nbsp; Team

<a name="sponsor"></a>
## ğŸ’°&nbsp; Sponsor
<div id="banner" style="overflow: hidden;justify-content:space-around;display:table-cell; vertical-align:middle; text-align:center">
  <div class="" style="max-width: 20%;max-height: 20%;display: inline-block;">
      <img width="14%" src="https://github.com/agemagician/ProtTrans/blob/master/images/1200px-Nvidia_image_logo.svg.png?raw=true" alt="nvidia logo">
  </div>

  <div class="" style="max-width: 20%;max-height: 20%;display: inline-block;">
      <img width="22%" src="https://github.com/agemagician/ProtTrans/blob/master/images/google-cloud-logo.jpg?raw=true" alt="google cloud logo">
  </div>

  <div class="" style="max-width: 20%;max-height: 20%;display: inline-block;">
      <img width="20%" src="https://github.com/agemagician/ProtTrans/blob/master/images/Oak_Ridge_National_Laboratory_logo.svg.png?raw=true" alt="ornl logo">
  </div>
  
  <div class="" style="max-width: 20%;max-height: 20%;display: inline-block;">
      <img width="12%" src="https://github.com/agemagician/ProtTrans/blob/master/images/SOFTWARE_CAMPUS_logo_cmyk.jpg?raw=true" alt="software campus logo">
  </div>
  
</div>


<a name="license"></a>
## ğŸ“˜&nbsp; License
The ProtTrans pretrained models are released under the under terms of the [MIT License](LICENSE).

<a name="citation"></a>
## âœï¸&nbsp; Citation
If you use this code or our pretrained models for your publication, please cite the original paper:
```
@inproceedings{elnnaggar2020prottrans,
  title = {{ProtTrans}: towards cracking the language of lifeâ€™s code through self-supervised deep learning and high performance computing},
  author = {Ahmed Elnaggar, Michael, .....},
  booktitle = {Arxiv},
  year = {2020},
  url = {https://arxiv/.....}
}
```
